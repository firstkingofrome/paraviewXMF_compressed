{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import dask\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import integrate\n",
    "import h5py\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "#raise the chunk size to better exploit the fact that seismo4 has tons of memory\n",
    "\n",
    "from dask.distributed import Client, LocalCluster,progress,performance_report,wait\n",
    "cluster = LocalCluster(n_workers=20) #,threads_per_worker=1\n",
    "client =Client(cluster)\n",
    "fullPath = os.getcwd()\n",
    "print(\"localhost:\"+str(client.scheduler_info()['services']['dashboard']))\n",
    "dask.config.set({'array.chunk-size': '2048MiB'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#essiOutputs = os.listdir('.')\n",
    "#essiOutputs = [i for i in essiOutputs if(\".hdf5\") in i][0]\n",
    "#essiOutputs = \"Location47faultNormalLarge.cycle=00000.essi\"\n",
    "essiOutputs = \"fullDomain1Hz.cycle=0000.essi\"\n",
    "sw4Output = h5py.File(essiOutputs,'r')\n",
    "print(\"timestep=\" +str(sw4Output['timestep'][0]))\n",
    "surfaceOnly = False\n",
    "dtStep = 10 #I am dumping all of them so that this works better within paraview\n",
    "#create a file name for the hdf5 paraview data\n",
    "dispFname = sw4Output.filename.split('/')[-1].split('.')[0]+\"DISP_PARAVIEW.hdf5\"\n",
    "rotFname = sw4Output.filename.split('/')[-1].split('.')[0]+\"ROT_PARAVIEW.hdf5\"\n",
    "#name of the directory to save the xmf outputs\n",
    "xmfOutputDir = \"dispXMFout\"\n",
    "zipOutputs = True #zip the xmf output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paraviewData = h5py.File(paraviewFname,'a')\n",
    "#get the dimensions\n",
    "h=sw4Output[\"ESSI xyz grid spacing\"][0]\n",
    "#just get surface [:,:,:,:surfaceElevation]\n",
    "Nx,Ny,Nz = sw4Output['vel_0 ijk layout'].shape[1],sw4Output['vel_0 ijk layout'].shape[2],sw4Output['vel_0 ijk layout'].shape[3]\n",
    "xOrg,yOrg,zOrg = sw4Output['ESSI xyz origin'][:]\n",
    "if surfaceOnly:\n",
    "    surfaceElevation=2\n",
    "    Nz=2\n",
    "else: \n",
    "    surfaceElevation=None\n",
    "timeSteps = sw4Output['vel_0 ijk layout'].shape[0]\n",
    "#sw4 time step\n",
    "dt = sw4Output['timestep'][:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data dumping step\n",
    "#preprocess the hdf5 file makeing a fucking snap for each time step since paraview that poorly desinged and documented\n",
    "\"\"\"\n",
    "try:\n",
    "    paraviewData.create_group(\"XparaviewSnaps\")\n",
    "    paraviewData.create_group(\"YparaviewSnaps\")\n",
    "    paraviewData.create_group(\"ZparaviewSnaps\")\n",
    "\n",
    "except ValueError:\n",
    "    del paraviewData[\"XparaviewSnaps\"]\n",
    "    del paraviewData[\"YparaviewSnaps\"]\n",
    "    del paraviewData[\"ZparaviewSnaps\"]\n",
    "\"\"\"\n",
    "#load up the origin\n",
    "#load up the sw4 origin\n",
    "sw4Xorigin,sw4Yorigin,sw4Zorigin = sw4Output[\"ESSI xyz origin\"][:]\n",
    "#close the paraview data so that I can access it directly from dask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#integrate the dask data with scipy cumtrapz\n",
    "def integrateDask(block,block_info=None,dt=dt):\n",
    "    #print(block.shape)\n",
    "    return integrate.cumtrapz(y=block,dx=dt,initial=0,axis=0)\n",
    "\n",
    "\n",
    "xDisp = da.from_array(sw4Output['vel_0 ijk layout'])\n",
    "yDisp = da.from_array(sw4Output['vel_1 ijk layout'])\n",
    "zDisp = da.from_array(sw4Output['vel_2 ijk layout'])\n",
    "#reformate array ranges to ditch data layers (if chosen)\n",
    "xDisp = xDisp[:,:,:,:surfaceElevation]\n",
    "yDisp = yDisp[:,:,:,:surfaceElevation]\n",
    "zDisp = zDisp[:,:,:,:surfaceElevation]\n",
    "\n",
    "print(\"lazy loaded complete domain\")\n",
    "print(\"instantiated dask arrays to correct range\")\n",
    "print(\"rechunked dask arrays\")\n",
    "\n",
    "#integrate\n",
    "xDisp = da.map_blocks(integrateDask,xDisp,dtype=np.float32)\n",
    "yDisp = da.map_blocks(integrateDask,yDisp,dtype=np.float32)\n",
    "zDisp = da.map_blocks(integrateDask,zDisp,dtype=np.float32)\n",
    "#flip z up and down to correct for difference in sw4 data\n",
    "zDisp = da.flip(zDisp,axis=3)\n",
    "print(\"lazy integrated\")\n",
    "### xarray dimensions\n",
    "dims = ['dt','x','y','z']\n",
    "coords = {'dt':np.arange(0,xDisp.shape[0],1),\"x\":np.arange(xOrg,xOrg+Nx*h,h),\"y\":np.arange(yOrg,yOrg+Ny*h,h),\"z\":np.arange(zOrg,zOrg+Nz*h,h)}\n",
    "### now convert these to xarray objects\n",
    "xDisp = client.persist(xr.DataArray(xDisp,dims=dims,coords=coords,name='xDisp'))\n",
    "wait(xDisp)\n",
    "xDisp.to_netcdf(dispFname,'w',group=\"xDisp\",encoding={'xDisp':{\"dtype\": \"float32\",'zlib': True,'complevel': 9}})\n",
    "\n",
    "del xDisp\n",
    "print(\"saved x Disp\")\n",
    "\n",
    "yDisp = client.persist(xr.DataArray(yDisp,dims=dims,coords=coords,name='yDisp'))\n",
    "yDisp.to_netcdf(dispFname,'a',group=\"yDisp\",encoding={'yDisp':{\"dtype\": \"float32\",'zlib': True,'complevel': 9}})\n",
    "wait(yDisp)\n",
    "print(\"saved y Disp\")\n",
    "del yDisp\n",
    "\n",
    "zDisp = client.persist(xr.DataArray(zDisp,dims=dims,coords=coords,name='zDisp'))\n",
    "wait(zDisp)\n",
    "zDisp.to_netcdf(dispFname,'a',group=\"zDisp\",encoding={'zDisp':{\"dtype\": \"float32\",'zlib': True,'complevel': 9}})\n",
    "print(\"saved z Disp\")\n",
    "del zDisp\n",
    "\n",
    "\"\"\"\n",
    "#save integrated results to the hdf5 file\n",
    "da.to_hdf5(paraviewFname,'/xDisp',xDisp)\n",
    "print(\"integrated and saved xDisp\")\n",
    "da.to_hdf5(paraviewFname,'/yDisp',yDisp)\n",
    "print(\"integrated and saved yDisp\")\n",
    "da.to_hdf5(paraviewFname,'/zDisp',zDisp)\n",
    "print(\"integrated and saved zDisp\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close the sw4 output\n",
    "sw4Output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is very slow if accessed as an xarray\n",
    "#xDisp,yDisp,zDisp = xr.open_dataarray(dispFname,group=\"xDisp\"),xr.open_dataset(dispFname,group=\"yDisp\"),xr.open_dataset(dispFname,group=\"zDisp\")\n",
    "dispData = h5py.File(dispFname,'r')\n",
    "xData,yData,zData = dispData['xDisp']['xDisp'][::dtStep,:,:,:],dispData['yDisp']['yDisp'][::dtStep,:,:,:],dispData['zDisp']['zDisp'][::dtStep,:,:,:]\n",
    "dispData.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the output directory for the individual hdf5 frames\n",
    "os.makedirs(xmfOutputDir,exist_ok=True)\n",
    "paraviewFnames = []\n",
    "#loop through each dask data set and save the results\n",
    "for t in range(xData.shape[0]):\n",
    "    #name the output data set\n",
    "    #what is this datas actual timestep?\n",
    "    dtValue = t*dtStep\n",
    "    displacementFilename = dispFname.split('_')[0]+\"dt=\"+str(dtValue)+dispFname.split('_')[1]\n",
    "    #create the output data set\n",
    "    xmfData = h5py.File(displacementFilename,'w')\n",
    "    #reshape these values to confrom to paraview coordinate shapes\n",
    "    zDispParaview = np.flip(zData[t,:,:,:],axis=0)  \n",
    "    #shape =x.shape\n",
    "    #x=x.reshape(x.shape[-1],x.shape[1],x.shape[0])\n",
    "    #y=y.reshape(y.shape[-1],y.shape[1],y.shape[0])\n",
    "    #zDispParaview = zDispParaview.reshape(zDispParaview.shape[-1],zDispParaview.shape[1],zDispParaview.shape[0])\n",
    "    xmfData.create_dataset('XparaviewSnaps', data=xData[t,:,:,:])\n",
    "    xmfData.create_dataset('YparaviewSnaps', data=yData[t,:,:,:])\n",
    "    xmfData.create_dataset('ZparaviewSnaps', data=zDispParaview)\n",
    "    paraviewFnames.append(xmfData.filename)\n",
    "    xmfData.close()\n",
    "    #use subprocess so that I dont have to wait on this\n",
    "    subprocess.Popen(\"mv \" + displacementFilename + \" ./\"+xmfOutputDir+\"/\"+displacementFilename,shell=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now save the output data to an xmf file\n",
    "### UPDATE THIS SO IT PULLS THIS INFORMATION FROM HDF5\n",
    "print(\"HardCoding data type\")\n",
    "print(\"SPACING IS SET TO 1\")\n",
    "#dtype = sw4Output[\"vel_0 ijk layout\"].dtype\n",
    "dtype=\"Float\"\n",
    "precision=\"4\"\n",
    "\n",
    "f = open(dispFname.split('.')[0]+\".xmf\", 'w')\n",
    "# Header for xml file\n",
    "f.write('''<?xml version=\"1.0\" ?>\n",
    "<!DOCTYPE Xdmf SYSTEM \"Xdmf.dtd\" []>\n",
    "<Xdmf Version=\"2.0\">\n",
    "<Domain>\n",
    "<Grid Name=\"Box\" GridType=\"Collection\" CollectionType=\"Temporal\">\n",
    "''')\n",
    "\n",
    "# loop over the attributes name written using time\n",
    "\n",
    "t = 0\n",
    "for files in range(len(paraviewFnames)):\n",
    "    # Naming datasets \n",
    "    dataSetName1 = paraviewFnames[files]+\":/XparaviewSnaps/\"\n",
    "    dataSetName2 = paraviewFnames[files]+\":/YparaviewSnaps/\"\n",
    "    dataSetName3 = paraviewFnames[files]+\":/ZparaviewSnaps/\"\n",
    "    # at individual time write the time independent Box grid. is it overdoing?\n",
    "    \n",
    "    f.write('''\n",
    "    <!-- time step -->\n",
    "    <Grid Name=\"Box %d\" GridType=\"Uniform\">  \n",
    "    <Topology TopologyType=\"3DCoRectMesh\" Dimensions=\"%d %d %d\"/>\n",
    "    <Geometry GeometryType=\"ORIGIN_DXDYDZ\">\n",
    "       <DataItem DataType=\"Float\" Dimensions=\"3\" Format=\"XML\">0.0 0.0 0.0</DataItem>\n",
    "       <DataItem DataType=\"Float\" Dimensions=\"3\" Format=\"XML\">%d %d %d</DataItem>\n",
    "    </Geometry>\n",
    "    <Time Value=\"%d\" />\n",
    "    \\n'''%(t, Nx, Ny, Nz,h,h,h, t))\n",
    "\n",
    "    #write z first, paraview doesnt work if i dont for unkown reasons!\n",
    "\n",
    "    f.write('''\\n\n",
    "    <Attribute Name=\"Z\" AttributeType=\"Scalar\" Center=\"Node\">\n",
    "    <DataItem Dimensions=\"%d %d %d\" NumberType=\"Float\" Precision=\"4\"\n",
    "    Format=\"HDF\">\n",
    "    %s\n",
    "    </DataItem>\n",
    "    </Attribute>\n",
    "    \\n'''%(Nx, Ny, Nz, dataSetName3))\n",
    "\n",
    "    # First Attribute\n",
    "    f.write('''\\n\n",
    "    <Attribute Name=\"X\" AttributeType=\"Scalar\" Center=\"Node\">\n",
    "    <DataItem Dimensions=\"%d %d %d\" NumberType=\"Float\" Precision=\"4\"\n",
    "    Format=\"HDF\">\n",
    "    %s\n",
    "    </DataItem>\n",
    "    </Attribute>\n",
    "    \\n'''%(Nx, Ny, Nz, dataSetName1))\n",
    "\n",
    "\n",
    "    # Second Attribute\n",
    "    f.write('''\\n\n",
    "    <Attribute Name=\"Y\" AttributeType=\"Scalar\" Center=\"Node\">\n",
    "    <DataItem Dimensions=\"%d %d %d \" NumberType=\"Float\" Precision=\"4\"\n",
    "    Format=\"HDF\">\n",
    "    %s\n",
    "    </DataItem>\n",
    "    </Attribute>\n",
    "    </Grid>\\n'''%(Nx, Ny, Nz, dataSetName2))\n",
    "    # Third Attribute\n",
    "    f.write('''\\n\n",
    "    <Attribute Name=\"Z\" AttributeType=\"Scalar\" Center=\"Node\">\n",
    "    <DataItem Dimensions=\"%d %d %d\" NumberType=\"Float\" Precision=\"4\"\n",
    "    Format=\"HDF\">\n",
    "    %s\n",
    "    </DataItem>\n",
    "    </Attribute>\n",
    "    \\n'''%(Nx, Ny, Nz, dataSetName3))\n",
    "\n",
    "\n",
    "\n",
    "    ### for some reason paraview wont read my last Z attribute unless there is a placehold\n",
    "    f.write('''\\n\n",
    "    <Attribute Name=\"ZBlank\" AttributeType=\"Scalar\" Center=\"Node\">\n",
    "    <DataItem Dimensions=\"%d %d %d\" NumberType=\"Float\" Precision=\"4\"\n",
    "    Format=\"HDF\">\n",
    "    %s\n",
    "    </DataItem>\n",
    "    </Attribute>\n",
    "    \\n'''%(Nz, Ny, Nx, dataSetName3))\n",
    "    \n",
    "    ### update timestep t\n",
    "    #print(t)\n",
    "    t += dtStep\n",
    "    \n",
    "\n",
    "\n",
    "# End the xmf file\n",
    "f.write('''\n",
    "   </Grid>\n",
    "</Domain>\n",
    "</Xdmf>\n",
    "''')\n",
    "f.flush()\n",
    "f.close()\n",
    "\n",
    "#move thie file to the output directory\n",
    "subprocess.Popen(\"mv \" + dispFname.split('.')[0]+\".xmf\" + \" ./\"+xmfOutputDir+\"/\"+dispFname.split('.')[0]+\".xmf\",shell=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### if requested compress the output\n",
    "if(zipOutputs): subprocess.Popen(\"zip -r \" + xmfOutputDir +\".zip \" + xmfOutputDir,shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
